{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-19T10:46:40.321302Z",
     "start_time": "2025-11-19T10:46:05.975213Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "ORIGINAL_FILE_PATH = 'data/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv'\n",
    "TEST_FILE_PATH = 'traffic_test_data.csv'\n",
    "TARGET_COLUMN = 'Label'\n",
    "SAMPLE_SIZE_PER_CLASS = 500  # Number of rows to sample for each class\n",
    "\n",
    "print(f\"Loading data from: {ORIGINAL_FILE_PATH}\")\n",
    "\n",
    "# Load the original data\n",
    "try:\n",
    "    df = pd.read_csv(ORIGINAL_FILE_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at {ORIGINAL_FILE_PATH}. Please check the path.\")\n",
    "    exit()\n",
    "\n",
    "# --- Data Cleaning (Consistency with Training) ---\n",
    "df.columns = df.columns.str.strip()\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "if TARGET_COLUMN not in df.columns:\n",
    "    print(f\"ERROR: Target column '{TARGET_COLUMN}' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Get the list of unique labels\n",
    "labels = df[TARGET_COLUMN].unique()\n",
    "print(f\"Found traffic labels: {labels}\")\n",
    "\n",
    "# --- Stratified Sampling ---\n",
    "sampled_data = []\n",
    "\n",
    "# Assuming the two main classes are 'Benign' and 'Bot' based on your context.\n",
    "# We iterate over all unique labels found.\n",
    "for label in labels:\n",
    "    class_df = df[df[TARGET_COLUMN] == label]\n",
    "\n",
    "    # Sample up to SAMPLE_SIZE_PER_CLASS or the total available count, whichever is smaller\n",
    "    sample_count = min(SAMPLE_SIZE_PER_CLASS, len(class_df))\n",
    "\n",
    "    # Use .sample() to select rows randomly\n",
    "    sampled_rows = class_df.sample(n=sample_count, random_state=42)\n",
    "    sampled_data.append(sampled_rows)\n",
    "    print(f\"  Sampled {sample_count} rows for label: '{label}'\")\n",
    "\n",
    "# Combine the sampled dataframes\n",
    "test_df = pd.concat(sampled_data).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the combined sample to a new CSV file\n",
    "test_df.to_csv(TEST_FILE_PATH, index=False)\n",
    "\n",
    "print(f\"\\n✅ Success! Test data generated with {len(test_df)} rows and saved to {TEST_FILE_PATH}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: data/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\n",
      "Found traffic labels: ['Benign' 'Bot']\n",
      "  Sampled 500 rows for label: 'Benign'\n",
      "  Sampled 500 rows for label: 'Bot'\n",
      "\n",
      "✅ Success! Test data generated with 1000 rows and saved to traffic_test_data.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T10:46:50.888855Z",
     "start_time": "2025-11-19T10:46:48.267874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_FILENAME = 'random_forest_traffic_classifier.pkl'\n",
    "UNLABELED_TEST_FILE_PATH = 'traffic_test_data.csv'  # <<< RENAME THIS TO YOUR FILE NAME!\n",
    "OUTPUT_FILE_PATH = 'unseen_predictions.csv'\n",
    "\n",
    "# Mapping the numerical predictions back to labels.\n",
    "# CRITICAL: This MUST match the LabelEncoder from your training phase.\n",
    "# Assuming 'Benign' was 0 and 'Bot' was 1 based on previous steps:\n",
    "PREDICTION_MAP = {\n",
    "    0: 'Benign',\n",
    "    1: 'Bot'\n",
    "}\n",
    "\n",
    "# --- 1. Load Model and Unlabeled Test Data ---\n",
    "print(f\"Loading model from {MODEL_FILENAME}...\")\n",
    "try:\n",
    "    with open(MODEL_FILENAME, 'rb') as file:\n",
    "        rf_model = pickle.load(file)\n",
    "    print(\"Model loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Model file {MODEL_FILENAME} not found.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loading unlabeled test data from {UNLABELED_TEST_FILE_PATH}...\")\n",
    "try:\n",
    "    X_unlabeled = pd.read_csv(UNLABELED_TEST_FILE_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Test data file {UNLABELED_TEST_FILE_PATH} not found.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Prepare Data for Prediction ---\n",
    "# This cleaning MUST be identical to the training data preparation.\n",
    "X_unlabeled.columns = X_unlabeled.columns.str.strip()\n",
    "X_unlabeled.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Handle Missing Values (Assuming you dropped NaNs in training):\n",
    "rows_before_cleaning = len(X_unlabeled)\n",
    "X_unlabeled.dropna(inplace=True)\n",
    "print(f\"Cleaned data: Dropped {rows_before_cleaning - len(X_unlabeled)} rows with NaN/Inf values.\")\n",
    "\n",
    "# Drop any non-numeric features (consistent with training)\n",
    "object_cols = X_unlabeled.select_dtypes(include=['object']).columns\n",
    "if len(object_cols) > 0:\n",
    "    X_unlabeled.drop(columns=object_cols, inplace=True)\n",
    "    print(f\"Dropped non-numeric columns: {list(object_cols)}\")\n",
    "\n",
    "# --- 3. Make Predictions ---\n",
    "print(\"\\nMaking predictions on the unseen data...\")\n",
    "# Ensure feature order/names match the training data!\n",
    "y_pred_encoded = rf_model.predict(X_unlabeled)\n",
    "y_predictions_labels = pd.Series(y_pred_encoded).map(PREDICTION_MAP)\n",
    "predictions_df = X_unlabeled.copy()\n",
    "predictions_df.reset_index(drop=True, inplace=True)\n",
    "predictions_df['Predicted_Label'] = y_predictions_labels\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "predictions_df.to_csv(OUTPUT_FILE_PATH, index=False)\n",
    "\n",
    "print(f\"\\n✅ Predictions complete. Results saved to {OUTPUT_FILE_PATH}\")\n",
    "print(f\"Total rows predicted: {len(predictions_df)}\")"
   ],
   "id": "e63b5344093b919",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from random_forest_traffic_classifier.pkl...\n",
      "Model loaded successfully.\n",
      "Loading unlabeled test data from traffic_test_data.csv...\n",
      "Cleaned data: Dropped 0 rows with NaN/Inf values.\n",
      "Dropped non-numeric columns: ['Timestamp', 'Label']\n",
      "\n",
      "Making predictions on the unseen data...\n",
      "\n",
      "✅ Predictions complete. Results saved to unseen_predictions.csv\n",
      "Total rows predicted: 1000\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
